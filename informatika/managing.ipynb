{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93708c03",
   "metadata": {},
   "source": [
    "## Susipažinimas\n",
    "Iš pradžių nebuvau tikras, kokie duomenys yra .tiff failuose, todėl nusprendžiau išsiaiškinti nelabai efektyviais būdais. Mažesnį failą nuskaitė per maždaug 10 sekundžių."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcefe537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import tifffile\n",
    "from PIL import Image\n",
    "import pptk\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2c5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failo nuskaitymo laikas: 10.684\n",
      "Matmenys: (31000, 38000)\n",
      "Duomenų tipas: uint16\n",
      "min: 0 max: 601\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "im = tifffile.imread('paseliai/clf_LIT_2021_ET100_18pas.tif')\n",
    "print(f'Failo nuskaitymo laikas:', round(time()-t, 3))\n",
    "print(f'Matmenys: {im.shape}')\n",
    "print(f'Duomenų tipas: {im.dtype}')\n",
    "print(f'min: {np.min(im)}', f'max: {np.max(im)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c99a0a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ee548",
   "metadata": {},
   "source": [
    "Ok, tik ką reiškia tie skaičiai? Galbūt tai kažkas panašaus į reljefo aukštį? Pasižiūrim 3D vaizdą. Tam parašiau gudrią komandą, dvimačio masyvo taškus paverčiančią į taškus, reikalingus 3D atvaizdavimui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "722f9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gudri_komanda(arr):\n",
    "    return np.swapaxes(np.array([*np.indices(arr.shape), arr]), 0, 2).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258166c",
   "metadata": {},
   "source": [
    "Tuomet pasinaudojau atvaizdavimo įrankiu [`pptk`](https://heremaps.github.io/pptk/viewer.html), skirtu vaizduoti dideliems taškų debesims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "982a9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_image = im[-4000:, 16000:20000] #Paimu fragmentą su 16M taškų\n",
    "xyz = gudri_komanda(small_image)\n",
    "xyz = xyz[xyz[:,2] != 0] #vaizduosiu tik taškus su nenulinėmis z koordinatėmis; jų yra apie 0.3M\n",
    "v = pptk.viewer(xyz)\n",
    "v.attributes(np.ones(xyz.shape))\n",
    "v.set(point_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a7721",
   "metadata": {},
   "source": [
    "Gavau tokį vaizdą:\n",
    "\n",
    "![](3D_points.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb414b49",
   "metadata": {},
   "source": [
    "Po kurio laiko supratau, kad kiekvienam taškui yra priskirtas sklypo ID, kuris dažniausiai būna 0. Kai jau viskas aišku, galima pereiti prie skaičiavimo, koks kievieno ID pasikartojimas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8a281",
   "metadata": {},
   "source": [
    "## Skaičiavimas ir jo optimizacija\n",
    "Kievieną skirtingą skaičiavimo algoritmą leidžiu ant $31000\\times 38000$ masyvo `im`, nuskaityto iš 99MB failo `clf_LIT_2021_ET100_18pas.tif`. \n",
    "\n",
    "Expected output:\n",
    "\n",
    "    {0: 934025302, 101: 11456189, 102: 6028877, 104: 4722672, 105: 4393260, 106: 13221637, 107: 70603190, 108: 12680311, 109: 2673109, 110: 1666446, 111: 29668404, 113: 3387695, 153: 6455884, 154: 1170747, 161: 47393, 201: 5414660, 203: 7592068, 205: 142835, 601: 62649321}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a399945",
   "metadata": {},
   "source": [
    "### `np.unique`, 2D case\n",
    "Vienas dažniausiai naudojamų metodų `np.unique`, taikomas dvimačiam masyvui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c4211ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_2D_numpy(a):\n",
    "    u, counts = np.unique(a, return_counts=True) #viename masyve ID, kitame jų dažnumai\n",
    "    return dict(zip(u, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f94900f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 18s ± 2.02 s per loop (mean ± std. dev. of 4 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 4 -n 1\n",
    "out = unique_2D_numpy(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eac557",
   "metadata": {},
   "source": [
    "### `np.unique`, 1D case\n",
    "Metodas `np.unique`, taikomas prieš tai paverčiant masyvą į vienmatį"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e18de2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_1D_numpy(a):\n",
    "    u, counts = np.unique(a.ravel(), return_counts=True) #viename masyve ID, kitame jų dažnumai\n",
    "    return dict(zip(u, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c567fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 21s ± 4.33 s per loop (mean ± std. dev. of 4 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 4 -n 1\n",
    "out = unique_1D_numpy(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a30f7f",
   "metadata": {},
   "source": [
    "Išvada: `np.unique` veikia vienodai lėtai ant to paties dydžio 1D ir 2D masyvų."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78e09f3",
   "metadata": {},
   "source": [
    "### `np.bincount`\n",
    "Metodas `np.bincount` veikia efektyviau už `np.unique`, kai yra nedidelė sveikųjų ID amplitudė. Tai patvirtina ir [šių matavimų rezultatai](https://stackoverflow.com/a/43096495/3044825). Jis grąžina skaičių nuo 0 iki `np.max(im)` dažnių sąrašą, iš kurio vėliau reikia išrinkti tik tuos, kurių dažnis nenulinis. **Svarbu: negalima `np.bincount` leisti ant didelių masyvų, nes viršijamas RAM, nuteka atmintis ir tai stipriai atsiliepia veikimo trukmei**. Todėl būtina skaidyti `im` į atskirus dvimačius masyvus ir sumuoti tarpinius skaičiavimų rezultatus. Prieš leidžiant `np.bincount` ant dvimačių masyvų svarbu juos prieš tai suplokštinti.\n",
    "\n",
    "Šiek tiek laiko galima sutaupyti pašalinant nulinius elementus naudojant `np.flatnonzero` metodą, grąžinantį nenulinių elementų indeksus. Tai daug efektyviau už nulinių elementų skaičiavimą `np.bincount` viduje. Vėliau nulių dažnis yra sužinomas atimant likusius dažnius iš `im` dydžio. \n",
    "\n",
    "`im` turi ~79% nulių, procesinimas pagreitėja ~21%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7babc998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def bincount_2D_numpy(arr, chunk_size = 1000, speed_up=False):\n",
    "    def bincount(a):\n",
    "        y = np.bincount(a)\n",
    "        ii = np.nonzero(y)[0]\n",
    "        return dict(zip(ii, y[ii]))\n",
    "    \n",
    "    c = Counter({})\n",
    "    for s1 in range(0, arr.shape[0], chunk_size):\n",
    "        for s2 in range(0, arr.shape[1], chunk_size):\n",
    "            chunk = arr[s1:s1+chunk_size, s2:s2+chunk_size].ravel() #2D masyvas paverčiamas į 1D\n",
    "            if speed_up:\n",
    "                cnt = bincount(chunk[np.flatnonzero(chunk)])\n",
    "            else:\n",
    "                cnt = bincount(chunk)\n",
    "            c = c + Counter(cnt)\n",
    "    out = dict(c)\n",
    "    if speed_up:\n",
    "        return {**{0:arr.size - sum(out.values())},**out}\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d376a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 s ± 846 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 7 -n 3\n",
    "out = bincount_2D_numpy(im, speed_up=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7889686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.4 s ± 350 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 7 -n 3\n",
    "out = bincount_2D_numpy(im, speed_up=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a66cdc",
   "metadata": {},
   "source": [
    "### Let's try numba\n",
    "[Some clues about it](https://stackoverflow.com/questions/46256279/bin-elements-per-row-vectorized-2d-bincount-for-numpy)\n",
    "\n",
    "Trivial case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2eeb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "def bincount_2D_numba(a, use_parallel=False, use_prange=False):\n",
    "    m, n = a.shape\n",
    "    counts = np.zeros(a.max()+1, dtype=int)\n",
    "    # Choose function based on args\n",
    "    func = bincount2D_numba_func0\n",
    "    if use_parallel:\n",
    "        if use_prange:\n",
    "            func = bincount2D_numba_func2\n",
    "        else:\n",
    "            func = bincount2D_numba_func1\n",
    "    # Run chosen function on input data and output\n",
    "    func(a, counts, m, n)    \n",
    "    ii = np.flatnonzero(counts)\n",
    "    return dict(zip(ii, counts[ii]))\n",
    "\n",
    "@njit\n",
    "def bincount2D_numba_func0(a, counts, m, n):\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            counts[a[i,j]] += 1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def bincount2D_numba_func1(a, counts, m, n):\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            counts[a[i,j]] += 1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def bincount2D_numba_func2(a, counts, m, n):\n",
    "    for i in prange(m):\n",
    "        for j in prange(n):\n",
    "            counts[a[i,j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cdd02b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "def bincount_1D_numba(a, use_parallel=False, use_prange=False):\n",
    "    m = len(a)\n",
    "    counts = np.zeros(a.max()+1, dtype=int)\n",
    "    # Choose function based on args\n",
    "    func = bincount1D_numba_func0\n",
    "    if use_parallel:\n",
    "        if use_prange:\n",
    "            func = bincount1D_numba_func2\n",
    "        else:\n",
    "            func = bincount1D_numba_func1\n",
    "    # Run chosen function on input data and output\n",
    "    func(a, counts, m)    \n",
    "    ii = np.flatnonzero(counts)\n",
    "    return dict(zip(ii, counts[ii]))\n",
    "\n",
    "@njit\n",
    "def bincount1D_numba_func0(a, counts, m):\n",
    "    for i in range(m):\n",
    "        counts[a[i]] += 1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def bincount1D_numba_func1(a, counts, m):\n",
    "    for i in range(m):\n",
    "        counts[a[i]] += 1\n",
    "\n",
    "@njit(parallel=True)\n",
    "def bincount1D_numba_func2(a, counts, m):\n",
    "    for i in prange(m):\n",
    "        counts[a[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67d12fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bincount_numba(arr, chunk_size = 10000, use_parallel=False, use_prange=False, ravel=False):\n",
    "    z = 0\n",
    "    c = Counter({})\n",
    "    for s1 in range(0, arr.shape[0], chunk_size):\n",
    "        for s2 in range(0, arr.shape[1], chunk_size):\n",
    "            chunk = arr[s1:s1+chunk_size, s2:s2+chunk_size]\n",
    "            if ravel:\n",
    "                cnt = bincount_1D_numba(chunk.ravel(), use_parallel=use_parallel, use_prange=use_prange)\n",
    "            else:\n",
    "                cnt = bincount_2D_numba(chunk, use_parallel=use_parallel, use_prange=use_prange)           \n",
    "            c = c + Counter(cnt)\n",
    "    out = dict(c)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bc80fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.22 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "out = bincount_numba(im, use_parallel=False, use_prange=False, ravel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a16070",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13593b2c",
   "metadata": {},
   "source": [
    "[Might large tiff?](https://gis.stackexchange.com/questions/268439/processing-large-geotiff-using-python/268452)  \n",
    "[More conqrete](https://gis.stackexchange.com/questions/402202/how-to-compress-split-a-tiff-file-4gb-in-order-to-work-with-it-in-python)  \n",
    "[GDAL installation](https://opensourceoptions.com/blog/how-to-install-gdal-with-anaconda/)  \n",
    "[Doing ReadAsArray fast](https://stackoverflow.com/questions/41742162/gdal-readasarray-for-vrt-extremely-slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a9d8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from osgeo import gdal\n",
    "\n",
    "def read_raster(path):\n",
    "    ds = gdal.OpenEx(path, gdal.GA_ReadOnly) #raster_dataset\n",
    "    gdal.AllRegister()\n",
    "    band = ds.GetRasterBand(1)\n",
    "    w1, w2 = band.GetBlockSize()\n",
    "    r1, r2 = range(0, ds.RasterXSize, w1), range(0, ds.RasterYSize, w2)\n",
    "    print(f'r1 = {r1}, r2 = {r2}, (w1, w2) = ({w1}, {w2})')\n",
    "    for i in r1:\n",
    "        for j in r2:\n",
    "            if j%1000==0: print(j, end=' ')\n",
    "            data = band.ReadAsArray(i, j, w1, w2) #x,y,xw,yw\n",
    "            #return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1 = range(0, 37942, 37942), r2 = range(0, 28659), (w1, w2) = (37942, 1)\n",
      "0 1000 2000 3000 4000 5000 6000 7000 8000 "
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "#read_raster(\"paseliai/clf_LIT_2021_ET100_18pas.tif\")\n",
    "data = read_raster(\"paseliai/paseliai_2020_sklypo_ID.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "998965b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<osgeo.gdal.Band; proxy of <Swig Object of type 'GDALRasterBandShadow *' at 0x000001DDCEF05960> >,\n",
       " (5000000.0, 10.0, 0.0, 3810000.0, 0.0, -10.0))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"paseliai/clf_LIT_2021_ET100_18pas.tif\"\n",
    "ds = gdal.OpenEx(path, gdal.GA_ReadOnly) #raster_dataset\n",
    "band = ds.GetRasterBand(1)\n",
    "band, ds.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b31edf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<osgeo.gdal.Band; proxy of <Swig Object of type 'GDALRasterBandShadow *' at 0x000001DDCEEF2510> >,\n",
       " (301730.0, 10.0, 0.0, 6258830.0, 0.0, -10.0))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"paseliai/paseliai_2020_sklypo_ID.tif\"\n",
    "ds = gdal.OpenEx(path, gdal.GA_ReadOnly) #raster_dataset\n",
    "band = ds.GetRasterBand(1)\n",
    "band, ds.GetGeoTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84c7ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ds.RasterXSize\n",
    "rows = ds.RasterYSize\n",
    "bands = ds.RasterCount\n",
    "geotransform = raster_dataset.GetGeoTransform() #6 items\n",
    "#top left x; w; rotation, 0 if image is \"north up\"; \n",
    "#top left y; rotation, 0 if image is \"north up\"; n-s pixel resolution\n",
    "\n",
    "originX = geotransform[0]\n",
    "originY = geotransform[3]\n",
    "pixelWidth = geotransform[1]\n",
    "pixelHeight = geotransform[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
